{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "- Script name: annotation_converter\n",
    "- Author: Dan Bright, cosmoid@tuta.io\n",
    "- Description: A script to convert formatting of annotations from spaCy to GPT\n",
    "\"\"\"\n",
    "\n",
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_files(directory_path: str) -> list[dict]:\n",
    "    \"\"\"Read all JSON files in the given directory and return their contents\n",
    "    as a list of python dictionaries.\"\"\"\n",
    "    annotations: list[dict] = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(directory_path, filename), \"r\") as file:\n",
    "                annotations.append(json.load(file))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gpt(spacy_annotations: list[dict]) -> list[dict]:\n",
    "    \"\"\"convert spaCy formatted annotations to GPT formatted.\"\"\"\n",
    "    gpt_annotations: list[dict] = []\n",
    "    prompt_separator: str = \"\\n\\n###\\n\\n\"\n",
    "    completion_separator: str = \"END\"\n",
    "    ent_class_separator: str = \"\\n\"\n",
    "    no_entity_token: str = \"NULL\"\n",
    "    for doc in spacy_annotations:\n",
    "        entity_classes: list = doc[\"classes\"]\n",
    "        for annotations in doc[\"annotations\"]:\n",
    "            if annotations:\n",
    "                prompt: str = annotations[0]\n",
    "                entities: list[list] = annotations[1][\"entities\"]\n",
    "                completion: str = \"\"\n",
    "                for cls in entity_classes:\n",
    "                    if cls not in [e[2] for e in entities]:\n",
    "                        completion += (\n",
    "                            f\"{cls}:['{no_entity_token}']{ent_class_separator}\"\n",
    "                        )\n",
    "                        pass\n",
    "                    else:\n",
    "                        tokens: list[str] = []\n",
    "                        for ent in entities:\n",
    "                            if cls == ent[2]:\n",
    "                                tokens.append(prompt[ent[0] : ent[1]])\n",
    "                        tokens_str: str = \",\".join([f\"'{token}'\" for token in tokens])\n",
    "                        cls_completion: str = (\n",
    "                            f\"{cls}:[{tokens_str}]{ent_class_separator}\"\n",
    "                        )\n",
    "                        completion += cls_completion\n",
    "                gpt_annotations.append(\n",
    "                    {\n",
    "                        \"prompt\": f\"{prompt}{prompt_separator}\",\n",
    "                        \"completion\": f\" {completion} {completion_separator}\",\n",
    "                    }\n",
    "                )\n",
    "    return gpt_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(annotations: list[dict], tmp_file: str, output_file: str) -> None:\n",
    "    \"\"\"Write annotations to file.\"\"\"\n",
    "    print(annotations)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for a in annotations:\n",
    "            json.dump(a, f)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "output_file = \"../annotations.jsonl\"\n",
    "tmp_file = \"../tmp.jsonl\"\n",
    "spacy_annotations = read_json_files(\"../../data/sample/train/json/\")\n",
    "# run function to convert spaCy formatted annotations to GPT formatted\n",
    "gpt_annotations = convert_to_gpt(spacy_annotations)\n",
    "# write output GPT formatted annotations to file\n",
    "write_to_file(gpt_annotations, tmp_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run openAI annotations preparation script (optional)\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "!openai tools fine_tunes.prepare_data -f annotations.jsonl -q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scu-GcmJu1Nh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
