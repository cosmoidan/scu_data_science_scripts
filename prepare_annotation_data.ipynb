{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "- Script name: prepare_annotation_data\n",
    "- Author: Dan Bright, cosmoid@tuta.io\n",
    "- Description: A script to prepare spreadsheet data for annotation.\n",
    "- Version 1.2\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re, html\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData:\n",
    "    \"\"\"\n",
    "    Class that cleans and prepares the data training &\n",
    "\n",
    "    Consumes:\n",
    "        - input_data: list[tuple] = list of input data to clean, in form [(record_id:int, text:str)]\n",
    "        - separate_slashes: bool = whether to separate slashes by a space [True|False]\n",
    "        - remove_linebreaks: bool = whether to remove linebreaks & join by a space [True|False]\n",
    "        - remove_non_alphanum: bool = whether to remove all non-alphanumeric characters [True|False]\n",
    "        - ensure_encoding: bool = ensure all characters are correctly encoded (True|False)\n",
    "    Produces:\n",
    "        - list of cleaned data, in form [(record_id:int, text:str)]\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(\n",
    "        cls,\n",
    "        input_data: list[tuple] = [],\n",
    "        separate_slashes: bool = True,  # Default to True\n",
    "        remove_linebreaks: bool = True,  # Default to True\n",
    "        remove_non_alphanum: bool = True,  # Default to True\n",
    "        ensure_encoding: bool = True,  # Default to True\n",
    "    ):\n",
    "        obj = super().__new__(cls)\n",
    "        return obj._run_filters(\n",
    "            docs=input_data,\n",
    "            separate_slashes=separate_slashes,\n",
    "            remove_linebreaks=remove_linebreaks,\n",
    "            remove_non_alphanum=remove_non_alphanum,\n",
    "            ensure_encoding=ensure_encoding,\n",
    "        )\n",
    "\n",
    "    def _run_filters(\n",
    "        self,\n",
    "        docs,\n",
    "        separate_slashes,\n",
    "        remove_linebreaks,\n",
    "        remove_non_alphanum,\n",
    "        ensure_encoding,\n",
    "    ) -> list[tuple]:\n",
    "        \"\"\"\n",
    "        Method to iterate the data & run filters.\n",
    "        Returns: list of cleaned data in form [(record_id:int, text:str)]\n",
    "        \"\"\"\n",
    "        filtered_docs: list[tuple] = []\n",
    "        for record in docs:\n",
    "            record_txt: str = record[1]\n",
    "            record_txt = (\n",
    "                self._separate_slashes(record_txt) if separate_slashes else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._remove_linebreaks(record_txt) if remove_linebreaks else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._remove_non_alphanum(record_txt)\n",
    "                if remove_non_alphanum\n",
    "                else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._ensure_encoding(record_txt) if ensure_encoding else record_txt\n",
    "            )\n",
    "            filtered_docs.append((record[0], record_txt))\n",
    "        return filtered_docs\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_encoding(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to ensure characters are encoded correctly\n",
    "        (i.e., no html entities, etc)\n",
    "        \"\"\"\n",
    "        return html.unescape(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def _separate_slashes(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to ensure all slashes within strings are surrounded by\n",
    "        whitespace.\n",
    "        \"\"\"\n",
    "        return re.sub(r\"(?<!\\s)/(?!\\s)\", \" / \", input)\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_linebreaks(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to remove paragraphs breaks.\n",
    "        \"\"\"\n",
    "        return \" \".join(input.splitlines())\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_non_alphanum(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to remove all non-alphanumeric characters, except:\n",
    "          - whitespaces\n",
    "          - dots\n",
    "          - forward slashes\n",
    "        \"\"\"\n",
    "        return re.sub(r\"\\s+\", \" \", re.sub(r\"[^\\w\\s\\.\\/]+\", \"\", input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareSample:\n",
    "    \"\"\"\n",
    "    Class to prepare a random sample of a given column (`target_header`) of spreadsheet data\n",
    "    for annotation.\n",
    "\n",
    "    Any row of the input spreadsheet where any value is missing from the defined `required_columns`\n",
    "    is dropped.\n",
    "\n",
    "    Note: To perform extra processing, simply add new methods following the pattern of\n",
    "    `_separate_slashes()`, and add the method to `__init__()`.\n",
    "\n",
    "    Takes:\n",
    "        - data_file: str = URL of the input data file.\n",
    "        - sample_output_xlsx: str = URL of output .xlsx file containing sample data.\n",
    "        - output_data_dir: str = URL of the txt output directory.\n",
    "        - exclude_prev_sample: str = URL of xlsx file containing previously sampled files (if any)\n",
    "        - exclude_id_header_map: tuple = maps headers of columns in exclude_sample and data_file; same values excluded in these\n",
    "        - sample_size: int = Size of the random sample (number of spreadsheet rows).\n",
    "        - target_header: str = Spreadsheet header of the column from which to extract data\n",
    "          for writing to output text (.txt) files.\n",
    "        - index_column_label: str = Name of the column in input spreadsheet containing row indices.\n",
    "        - required_columns: dict[str:str] = Dictionary of columns to be retained in the\n",
    "          output .xlsx file, in form {\"original column name\": \"output column name\"}.\n",
    "        - write_xlsx: bool = Defines whether to write an output excel file (.xlsx). True|False.\n",
    "        - write_txt: bool = Defines whether to write & save text files for each row's\n",
    "          target_header column.\n",
    "    Provides:\n",
    "        - Method to ensure all slashes in a text string are surrounded by whitespace.\n",
    "        - One text file (.txt) per randomly selected spreadsheet row, containing the\n",
    "          appropriately formatted text extracted from the specified spreadsheet column (target_header),\n",
    "          to be saved in the output directory.\n",
    "        - One excel file (.xlsx) containing the randomly selected spreadsheet rows, with the only the\n",
    "          require_columns included.\n",
    "    Returns:\n",
    "        - None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_file: str,\n",
    "        sample_output_xlsx: str,\n",
    "        output_data_dir: str,\n",
    "        exclude_prev_sample: str,\n",
    "        exclude_id_header_map: tuple,\n",
    "        sample_size: int,\n",
    "        target_header: str,\n",
    "        index_column_label: str,\n",
    "        required_columns: dict[str:str],\n",
    "        write_xlsx: bool,\n",
    "        write_txt_files: bool,\n",
    "    ) -> None:\n",
    "        self._data_file: Path = Path(data_file).resolve(strict=True)\n",
    "        self._sample_output_xlsx: str = sample_output_xlsx\n",
    "        self._output_data_dir: Path = Path(output_data_dir).resolve(strict=False)\n",
    "        self._exclude_prev_sample: Path = Path(exclude_prev_sample).resolve(\n",
    "            strict=False\n",
    "        )\n",
    "        self._exclude_id_header_map: tuple = exclude_id_header_map\n",
    "        self._sample_size: int = sample_size\n",
    "        self._target_header: str = target_header\n",
    "        self._required_columns: dict[str:str] = required_columns\n",
    "        self._index_column_label: str = index_column_label\n",
    "        self._random_sample: list[tuple] = []\n",
    "        self._df_sel: pd.DataFrame = None\n",
    "        self._df_sample: pd.DataFrame = None\n",
    "        self._get_data()\n",
    "        self._get_random_sample()\n",
    "        if self._random_sample:\n",
    "            # ADD PROCESSING METHODS _BELOW_ THIS LINE\n",
    "            self._random_sample = CleanData(self._random_sample)\n",
    "            # _DO_NOT_ ADD ANYTHING _BELOW_ THIS LINE\n",
    "            self._write_to_xlsx() if write_xlsx else None\n",
    "            self._to_txt_files() if write_txt_files else None\n",
    "\n",
    "    def _get_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Method to extract cells from excel spreadsheet column.\n",
    "          - Only extracts columns passed into class as `required_columns`.\n",
    "          - Drops rows where any value is missing from `required_columns`.\n",
    "        \"\"\"\n",
    "        pd.options.mode.use_inf_as_na = True\n",
    "        df: pd.DataFrame = pd.read_excel(self._data_file)\n",
    "        self._df_sel = df[[c for c in self._required_columns]].copy()\n",
    "        self._df_sel.dropna(axis=0, inplace=True)\n",
    "        print(f\"{len(self._df_sel.index)} valid records have been initially extracted\")\n",
    "\n",
    "    def _get_random_sample(self) -> None:\n",
    "        \"\"\"\n",
    "        Method to return random sample from a list of strings, as [(index (starting @ 1)), string)].\n",
    "        \"\"\"\n",
    "        if self._exclude_prev_sample:\n",
    "            df_prev: pd.DataFrame = pd.read_excel(self._exclude_prev_sample)\n",
    "            values_to_exclude: list = df_prev[self._exclude_id_header_map[0]].to_list()\n",
    "            self._df_sel = self._df_sel[\n",
    "                self._df_sel[self._exclude_id_header_map[1]].isin(values_to_exclude)\n",
    "                == False\n",
    "            ]\n",
    "        try:\n",
    "            self._df_sample = self._df_sel.sample(n=self._sample_size)\n",
    "            for idx in range(self._sample_size):\n",
    "                self._random_sample.append(\n",
    "                    (\n",
    "                        self._df_sample.iloc[idx][self._index_column_label].astype(int),\n",
    "                        self._df_sample.iloc[idx][self._target_header],\n",
    "                    )\n",
    "                )\n",
    "        except ValueError as e:\n",
    "            print(\n",
    "                f\"\"\"\n",
    "                Operation terminated; a sample could not be obtained.\n",
    "\n",
    "                Looks like there were not enough valid records to create a \n",
    "                sample of the required size.\n",
    "                \n",
    "                Additional info: '{str(e)}.'\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "    def _write_to_xlsx(self):\n",
    "        \"\"\"\n",
    "        Method to write the required columns from the sample to a .xlsx file.\n",
    "        \"\"\"\n",
    "        # ensure index column is type INT\n",
    "        self._df_sample[self._index_column_label] = self._df_sample[\n",
    "            self._index_column_label\n",
    "        ].astype(int)\n",
    "        # sort by index column\n",
    "        self._df_sample.sort_values(by=self._index_column_label, inplace=True)\n",
    "        # rename columns if required\n",
    "        self._df_sample.rename(columns=self._required_columns, inplace=True)\n",
    "        # write to excel\n",
    "        self._df_sample.to_excel(self._sample_output_xlsx, index=False)\n",
    "\n",
    "    def _to_txt_files(self) -> None:\n",
    "        \"\"\"\n",
    "        Method to write each list entry to a .txt file.\n",
    "        \"\"\"\n",
    "        for record in self._random_sample:\n",
    "            with open(self._output_data_dir / f\"record_{record[0]}.txt\", \"w\") as file:\n",
    "                file.write(record[1])\n",
    "        print(f\"Text files written in {self._output_data_dir}. Job done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"define paths & parameters\"\"\"\n",
    "\n",
    "# location of input data xlsx\n",
    "DATA_FILE: str = \"../../data/input/WIP_RP_VERSION_3a.xlsx\"\n",
    "# where to save output sample xlsx (note: saved in input dir, as still input data (sample of))\n",
    "SAMPLE_OUTPUT_XLSX: str = \"../../data/input/test_sample_1.xlsx\"\n",
    "# where to save output txt files\n",
    "OUTPUT_DATA_DIR: str = \"../../data/sample/test/txt\"\n",
    "# loc of xlsx of prev sampled rcds\n",
    "EXCLUDE_PREV_SAMPLE: str = \"../../data/input/test_sample_1.xlsx\"\n",
    "# column header name of values to exclude -\n",
    "# mapped as (header in prev sampled (`EXCLUDE_PREV_SAMPLE`), header in input data `DATA_FILE`)\n",
    "EXCLUDE_ID_HEADER_MAP: tuple = (\n",
    "    \"RECORD_ID\",\n",
    "    \"RecNum\",\n",
    ")\n",
    "# name of header of column to extract values from\n",
    "TARGET_HEADER: str = \"CLEANED Summary\"\n",
    "# name of header of the column to be regarded as record index or ID\n",
    "INDEX_COLUMN_LABEL: str = \"RecNum\"\n",
    "# whether to write the selected sample to a new output excel file\n",
    "WRITE_XLSX: bool = True\n",
    "# whether to write the values from selected TARGET_HEADER column to text files\n",
    "WRITE_TXT_FILES: bool = True\n",
    "# columns required to be imported -\n",
    "#   in form {original col name: output col name for output xlsx file (can be same)}\n",
    "REQUIRED_COLUMNS: list[str] = {\n",
    "    INDEX_COLUMN_LABEL: \"RECORD_ID\",\n",
    "    TARGET_HEADER: \"SUMMARY\",\n",
    "}\n",
    "# size of sample\n",
    "SAMPLE_SIZE: int = 25\n",
    "\n",
    "\"\"\"extract & prepare sample of report data for annotation\"\"\"\n",
    "\n",
    "PrepareSample(\n",
    "    data_file=DATA_FILE,\n",
    "    sample_output_xlsx=SAMPLE_OUTPUT_XLSX,\n",
    "    output_data_dir=OUTPUT_DATA_DIR,\n",
    "    exclude_prev_sample=EXCLUDE_PREV_SAMPLE,\n",
    "    exclude_id_header_map=EXCLUDE_ID_HEADER_MAP,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    target_header=TARGET_HEADER,\n",
    "    index_column_label=INDEX_COLUMN_LABEL,\n",
    "    required_columns=REQUIRED_COLUMNS,\n",
    "    write_xlsx=WRITE_XLSX,\n",
    "    write_txt_files=WRITE_TXT_FILES,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scu-GcmJu1Nh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
