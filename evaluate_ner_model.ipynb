{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "- Script name: evaluate_model.\n",
    "- Author: Dan Bright, cosmoid@tuta.io.\n",
    "- Description: A script to evaluate performance of NER models\n",
    "- Version: 0.1\n",
    "\"\"\"\n",
    "\n",
    "# declare imports\n",
    "import os, re, json, html\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData:\n",
    "    \"\"\"\n",
    "    Class that cleans and prepares the data training &\n",
    "\n",
    "    Consumes:\n",
    "        - input_data: list[tuple] = list of input data to clean, in form [(record_id:int, text:str)]\n",
    "        - separate_slashes: bool = whether to separate slashes by a space [True|False]\n",
    "        - remove_linebreaks: bool = whether to remove linebreaks & join by a space [True|False]\n",
    "        - remove_non_alphanum: bool = whether to remove all non-alphanumeric characters [True|False]\n",
    "        - ensure_encoding: bool = ensure all characters are correctly encoded (True|False)\n",
    "    Produces:\n",
    "        - list of cleaned data, in form [(record_id:int, text:str)]\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(\n",
    "        cls,\n",
    "        input_data: list[tuple] = [],\n",
    "        separate_slashes: bool = True,  # Default to True\n",
    "        remove_linebreaks: bool = True,  # Default to True\n",
    "        remove_non_alphanum: bool = True,  # Default to True\n",
    "        ensure_encoding: bool = True,  # Default to True\n",
    "    ) -> list[tuple]:\n",
    "        obj = super().__new__(cls)\n",
    "        return obj._run_filters(\n",
    "            docs=input_data,\n",
    "            separate_slashes=separate_slashes,\n",
    "            remove_linebreaks=remove_linebreaks,\n",
    "            remove_non_alphanum=remove_non_alphanum,\n",
    "            ensure_encoding=ensure_encoding,\n",
    "        )\n",
    "\n",
    "    def _run_filters(\n",
    "        self,\n",
    "        docs,\n",
    "        separate_slashes,\n",
    "        remove_linebreaks,\n",
    "        remove_non_alphanum,\n",
    "        ensure_encoding,\n",
    "    ) -> list[tuple]:\n",
    "        \"\"\"\n",
    "        Method to iterate the data & run filters.\n",
    "        Returns: list of cleaned data in form [(record_id:int, text:str)]\n",
    "        \"\"\"\n",
    "        filtered_docs: list[tuple] = []\n",
    "        for record in docs:\n",
    "            record_txt: str = record[1]\n",
    "            record_txt = (\n",
    "                self._separate_slashes(record_txt) if separate_slashes else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._remove_linebreaks(record_txt) if remove_linebreaks else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._remove_non_alphanum(record_txt)\n",
    "                if remove_non_alphanum\n",
    "                else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._ensure_encoding(record_txt) if ensure_encoding else record_txt\n",
    "            )\n",
    "            filtered_docs.append((record[0], record_txt))\n",
    "        return filtered_docs\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_encoding(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to ensure characters are encoded correctly\n",
    "        (i.e., no html entities, etc)\n",
    "        \"\"\"\n",
    "        return html.unescape(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def _separate_slashes(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to ensure all slashes within strings are surrounded by\n",
    "        whitespace.\n",
    "        \"\"\"\n",
    "        return re.sub(r\"(?<!\\s)/(?!\\s)\", \" / \", input)\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_linebreaks(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to remove paragraphs breaks.\n",
    "        \"\"\"\n",
    "        return \" \".join(input.splitlines())\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_non_alphanum(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to remove all non-alphanumeric characters, except:\n",
    "          - whitespaces\n",
    "          - dots\n",
    "          - forward slashes\n",
    "        \"\"\"\n",
    "        return re.sub(r\"\\s+\", \" \", re.sub(r\"[^\\w\\s\\.\\/]+\", \"\", input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateModel:\n",
    "    \"\"\"\n",
    "    Class that evaluates performance of NER models.\n",
    "\n",
    "    Consumes:\n",
    "        - jupyter: bool = whether script is being run as a Jupyter notebook (True|False)\n",
    "        - debug_output = whether to write verbose processing output to STDOUT for debug (True|False)\n",
    "        - output_json_path = Path to output JSON (string)\n",
    "        - output_xlsx_path = Path to output XLSX (string)\n",
    "        - ner_record_id_key = key of record ID field in NER JSON (string)\n",
    "        - anno_record_id_key = key of record ID field in annotation JSON (string)\n",
    "        - ner_json_path: str = path to JSON file containing NER results (string)\n",
    "        - anno_json_path: str = path to JSON file containing the annotated data (string)\n",
    "        - export_json: str = write results output to JSON file? (True|False)\n",
    "        - export_xlsx: str = write results output to XLSX file? (True|False)\n",
    "    Produces:\n",
    "        - results: dict = python dictionary containing results metrics for the input corpus,\n",
    "          comprising of:\n",
    "            - true positives\n",
    "            - false positives\n",
    "            - false negatives\n",
    "            - total number of extracted entities\n",
    "            - precision\n",
    "            - recall\n",
    "            - f1-score\n",
    "    Notes:\n",
    "        - input JSON MUST be in the form as per this example:\n",
    "          [{\"RECORD_ID\": 280, \"ICDT_DATE\": [\"2015/05/03\", \"May 3 2015\"], \"ICDT_TIME\": [\"0330Z\"]}]\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(\n",
    "        cls,\n",
    "        jupyter: bool = True,  # default True\n",
    "        debug_output: bool = True,  # default True\n",
    "        output_json_path: str = \"\",\n",
    "        output_xlsx_path: str = \"\",\n",
    "        ner_record_id_key: str = \"\",\n",
    "        anno_record_id_key: str = \"\",\n",
    "        ner_json_path: str = \"\",\n",
    "        anno_json_path: str = \"\",\n",
    "        export_json: bool = False,  # default False\n",
    "        export_xlsx: bool = False,  # default False\n",
    "    ) -> dict:\n",
    "        obj = super().__new__(cls)\n",
    "        # define variables\n",
    "        obj._jupyter: bool = jupyter\n",
    "        obj._debug_output: bool = debug_output\n",
    "        obj._output_json_path: Path = Path(output_json_path).resolve(strict=False)\n",
    "        obj._output_xlsx_path: Path = Path(output_xlsx_path).resolve(strict=False)\n",
    "        obj._ner_record_id_key: str = ner_record_id_key\n",
    "        obj._anno_record_id_key: str = anno_record_id_key\n",
    "        obj._ner_json_path: Path = Path(ner_json_path).resolve(strict=True)\n",
    "        obj._anno_json_path: Path = Path(anno_json_path).resolve(strict=True)\n",
    "        obj._export_json: str = export_json\n",
    "        obj._export_xlsx: str = export_xlsx\n",
    "        obj._data_ner: dict = {}\n",
    "        obj._data_anno: dict = {}\n",
    "        obj._analytics_data: dict = {}\n",
    "        obj._results: OrderedDict = OrderedDict()\n",
    "        obj._unprocessed: list = []\n",
    "        # run methods [note: do not change running order]\n",
    "        obj._load_data()\n",
    "        obj._analyze_data()\n",
    "        obj._calculate_stats()\n",
    "        return obj._get_results()\n",
    "\n",
    "    def _pdb(self, string: str) -> None:\n",
    "        # method to print debug strings if requested\n",
    "        print(string) if self._debug_output else None\n",
    "\n",
    "    def _load_data(self) -> None:\n",
    "        # loads & sorts incoming json to python dict\n",
    "        with open(self._ner_json_path, \"r\") as file:\n",
    "            self._data_ner = json.load(file)\n",
    "        with open(self._anno_json_path, \"r\") as file:\n",
    "            self._data_anno = json.load(file)\n",
    "        self._data_anno = sorted(\n",
    "            self._data_anno, key=lambda x: x[self._anno_record_id_key]\n",
    "        )\n",
    "        self.data_ner = sorted(self._data_ner, key=lambda x: x[self._ner_record_id_key])\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_one_occurrence(lst: list, value: str) -> list:\n",
    "        # method to remove 1st occurrence of value from list\n",
    "        if value in lst:\n",
    "            index = lst.index(value)\n",
    "            return lst[:index] + lst[index + 1 :]\n",
    "        return lst\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_phrase(phrase: str, tokens: list[str]) -> bool:\n",
    "        for token in tokens:\n",
    "            # if re.search(rf\"\\b{re.escape(phrase)}\\b\", token):\n",
    "            if phrase == token:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _analyze_data(self) -> None:\n",
    "        # method to compare NER results to annotations\n",
    "        true_positive: int = 0  # retrieved for entity class matches annotated\n",
    "        false_positive: int = 0  # retrieved for entity class not in annotated\n",
    "        false_negative: int = 0  # not retrieved for entity class but in annotated\n",
    "        total_extracted: int = 0  # total entities extracted\n",
    "        self._unprocessed = list(\n",
    "            set([r[self._anno_record_id_key] for r in self._data_anno]).difference(\n",
    "                set([r[self._ner_record_id_key] for r in self._data_ner])\n",
    "            )\n",
    "        )\n",
    "        for record in zip(self._data_ner, self._data_anno):\n",
    "            extr_ents: dict = record[0]\n",
    "            anno_ents: dict = record[1]\n",
    "            e_id: int = extr_ents.pop(self._ner_record_id_key, None)  # rec ID extracted\n",
    "            a_id: int = anno_ents.pop(\n",
    "                self._anno_record_id_key, None\n",
    "            )  # rec ID annotated\n",
    "            if e_id == a_id:\n",
    "                self._pdb(f\"\\n{self._ner_record_id_key}: {e_id}\")\n",
    "                e_clses: list = list(extr_ents.keys())\n",
    "                a_clses: list = list(anno_ents.keys())\n",
    "                for ent_cls in e_clses:\n",
    "                    total_extracted += len(\n",
    "                        [e for e in extr_ents[ent_cls] if e != \"NULL\"]\n",
    "                    )\n",
    "                    if ent_cls in a_clses:\n",
    "                        e_toks: list = [\n",
    "                            CleanData([(e_id, t.upper())])[0][1]\n",
    "                            for t in extr_ents[ent_cls]\n",
    "                        ]\n",
    "                        a_toks: list = [\n",
    "                            CleanData([(a_id, t.upper())])[0][1]\n",
    "                            for t in anno_ents[ent_cls]\n",
    "                        ]\n",
    "                        for e_tok in e_toks:\n",
    "                            if self._check_phrase(e_tok, a_toks):\n",
    "                                self._pdb(f\"TRUE POS: '{e_tok}' is in {a_toks}\")\n",
    "                                a_toks = self._remove_one_occurrence(a_toks, e_tok)\n",
    "                                true_positive += 1\n",
    "                            else:\n",
    "                                if e_tok != \"NULL\":\n",
    "                                    self._pdb(f\"FALSE POS: '{e_tok}' not in {a_toks}\")\n",
    "                                    false_positive += 1\n",
    "                        if a_toks:  # if any outstanding remain in list\n",
    "                            self._pdb(\n",
    "                                f\"FALSE NEG: These tokens for {ent_cls} were not retrieved by NER: {a_toks}\"\n",
    "                            )\n",
    "                            false_negative += len(a_toks)\n",
    "                    else:\n",
    "                        e_toks = [\n",
    "                            CleanData([(e_id, t.upper())])[0][1]\n",
    "                            for t in extr_ents[ent_cls]\n",
    "                        ]\n",
    "                        for token in e_toks:\n",
    "                            if token != \"NULL\":\n",
    "                                self._pdb(\n",
    "                                    f\"FALSE POS: Extracted token(s) '{e_toks}' for {ent_cls} do not exist in annotation.\"\n",
    "                                )\n",
    "                                false_positive += 1\n",
    "            else:\n",
    "                self._pdb(\n",
    "                    f\"Aborting analysis for annotated record {a_id} & extracted record {e_id}: IDs do not match!\"\n",
    "                )\n",
    "        self._analytics_data.update(\n",
    "            {\n",
    "                \"true_positive\": true_positive,\n",
    "                \"false_positive\": false_positive,\n",
    "                \"false_negative\": false_negative,\n",
    "                \"total_extracted\": total_extracted,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _calculate_stats(self) -> None:\n",
    "        # method to calculate the stats\n",
    "        # {'true_positive': 50, 'false_positive': 32, 'false_negative': 52, 'total_extracted': 82}\n",
    "        tp: int = self._analytics_data[\"true_positive\"]\n",
    "        fp: int = self._analytics_data[\"false_positive\"]\n",
    "        fn: int = self._analytics_data[\"false_negative\"]\n",
    "        te: int = self._analytics_data[\"total_extracted\"]\n",
    "        precision: float = tp / te if tp > 0 else 1.0 if (fn == 0 and te == 0) else 0\n",
    "        recall: float = (\n",
    "            tp / (tp + fn) if tp > 0 else 1.0 if (fn == 0 and te == 0) else 0\n",
    "        )\n",
    "        f1_score: float = (\n",
    "            ((2 * precision * recall) / (precision + recall))\n",
    "            if (precision > 0 and recall > 0)\n",
    "            else 1.0\n",
    "            if (tp == 0 and fn == 0 and te == 0)\n",
    "            else 0\n",
    "        )\n",
    "        self._results.update(\n",
    "            {\n",
    "                \"true_positive\": tp,\n",
    "                \"false_positive\": fp,\n",
    "                \"false_negative\": fn,\n",
    "                \"total_extracted\": te,\n",
    "                \"precision\": round(precision, 2),\n",
    "                \"recall\": round(recall, 2),\n",
    "                \"f1_score\": round(f1_score, 2),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _get_results(self) -> dict:\n",
    "        return self._results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script\n",
    "\n",
    "# script parameters\n",
    "JUPYTER: bool = True  # running on Jupyter notebook? (True|False)\n",
    "NER_RESULT_JSON: str = \"../../data/output/ner/test_result_gpt_1.json\"  # path to json file containing NER results\n",
    "ANNOTATIONS_JSON: str = \"../../data/output/prepared_anno/test_sample_1_annotated.json\"  # path to json file containing the annotated data\n",
    "NER_RECORD_ID_KEY: str = \"RECORD_ID\"  # key of record ID field in NER JSON\n",
    "ANNO_RECORD_ID_KEY: str = \"RECORD_ID\"  # key of record ID field in annotation JSON\n",
    "EXPORT_JSON: bool = True  # write results output to JSON file? (True|False)\n",
    "EXPORT_XLSX: bool = True  # write results output to XLSX file? (True|False)\n",
    "OUTPUT_JSON_PATH: str = \"../../data/output/eval/test_eval_gpt_1.json\"  # path > output JSON\n",
    "OUTPUT_XLSX_PATH: str = \"../../data/output/eval/test_eval_gpt_1.xlsx\"  # path > output XLSX\n",
    "DEBUG_OUTPUT: bool = False  # whether to write verbose debug output to STDOUT\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = EvaluateModel(\n",
    "        jupyter=JUPYTER,\n",
    "        debug_output=DEBUG_OUTPUT,\n",
    "        output_json_path=OUTPUT_JSON_PATH,\n",
    "        output_xlsx_path=OUTPUT_XLSX_PATH,\n",
    "        ner_record_id_key=NER_RECORD_ID_KEY,\n",
    "        anno_record_id_key=ANNO_RECORD_ID_KEY,\n",
    "        ner_json_path=NER_RESULT_JSON,\n",
    "        anno_json_path=ANNOTATIONS_JSON,\n",
    "        export_json=EXPORT_JSON,\n",
    "        export_xlsx=EXPORT_XLSX,\n",
    "    )\n",
    "\n",
    "    pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scu-GcmJu1Nh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
