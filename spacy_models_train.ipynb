{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rWgjJdhqOZn"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "- Script name: spacy_models_train\n",
        "- Author: Dan Bright, cosmoid@tuta.io\n",
        "- Description: A script to train spaCy \n",
        "  language models for NER\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "!pip install spacy spacy-transformers  # install transformers\n",
        "#!python -m spacy download en_core_web_lg  # install base spaCy CNN model\n",
        "!python -m spacy download en_core_web_trf  # install base spaCy transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DaeTdUDnS1n"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import spacy, json, glob, os, random\n",
        "from spacy.tokens import DocBin\n",
        "from spacy.util import filter_spans\n",
        "from tqdm import tqdm\n",
        "import locale\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"  # Fix Colab local bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUc--y07nS1r"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "\n",
        "def get_annotation_file_handles(train_url, ext, print_output=True):\n",
        "    global annotated_files\n",
        "\n",
        "    def construct_handles(url):\n",
        "      # ensure url has trailing slash\n",
        "      url = url + '/' if url[-1:] != '/' else url\n",
        "      # load hand annotated examples\n",
        "      annotated_files = glob.glob(url + f'*.{ext}')\n",
        "      # sort based on filename\n",
        "      annotated_files.sort(key=lambda x: os.path.basename(x))\n",
        "      # print counted files to demonstrate success\n",
        "      if print_output:\n",
        "          print(f'Number of annotated files: {len(annotated_files)}')\n",
        "      return annotated_files\n",
        "    \n",
        "    # construct handles for training data\n",
        "    annotated_files = construct_handles(train_url)\n",
        "\n",
        "def json_to_doc(print_output=False):\n",
        "    # Load json into list of Python dicts\n",
        "    global annotations\n",
        "    def create_json(json_files):\n",
        "      anno = []\n",
        "      for f in json_files:\n",
        "          with open(f, 'r', encoding='utf-8') as file:\n",
        "              anno.append(json.loads(file.read()))\n",
        "      if print_output:\n",
        "          # print count of annotation dicts to verify success\n",
        "          print(f'Number of annotations in files: {len(anno)}')\n",
        "          # print first element (document), to verify\n",
        "          print(f'Annotation sample: {anno[:1]}')\n",
        "      return anno\n",
        "    annotations = create_json(annotated_files)\n",
        "\n",
        "def test_train_split(print_output=False):\n",
        "    global annotations_training, annotations_dev\n",
        "    random.shuffle(annotations)\n",
        "    annotations_training = annotations[0:int(len(annotations)*0.8)]\n",
        "    annotations_dev = annotations[len(annotations_training):]\n",
        "    print(f'\\nTraining data is {len(annotations_training)} documents, dev data is {len(annotations_dev)} documents.\\n') if print_output else None\n",
        "    print(f'\\nFirst training document (to test randomisation): {annotations_training[0]}\\n') if print_output else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDo6ld3inS1s"
      },
      "outputs": [],
      "source": [
        "def setup(print_output=0, colab=0):\n",
        "    \"\"\"globals set here\"\"\"\n",
        "    global annotated_files, labels_of_interest, docbin_object_path, docbin_object_training_filename, docbin_object_dev_filename\n",
        "    google_drive_path = '/content/drive/MyDrive/'\n",
        "    annotations_data_path = f'{google_drive_path if colab else \"./\"}data/train/json'\n",
        "    annotations_data_filetype = 'json'\n",
        "    docbin_object_path = f'{google_drive_path if colab else \"./\"}data/docbin/'  # important: remember trailing slash\n",
        "    docbin_object_training_filename = 'training_data.spacy'\n",
        "    docbin_object_dev_filename = 'dev_data.spacy'\n",
        "    # define entity labels of interest\n",
        "    labels_of_interest = ['ATC_CITY', 'ATC_STATE', 'ICDT_DATE', 'ICDT_TIME', 'ICDT_LOC', 'UAS_COLOR', 'UAS_SHAPE',\n",
        "                          'UAS_HEADING', 'UAS_SIZE', 'UAS_REL_ALT', 'UAS_ACT_ALT', 'AC_ALT', 'AC_TYPE', 'AC_HEADING', 'FT_NAME','FL_OPTOR','FT_ROUTE']\n",
        "    # run setup functions\n",
        "    get_annotation_file_handles(annotations_data_path, annotations_data_filetype, print_output)\n",
        "    json_to_doc(print_output)\n",
        "    # split into train and dev data\n",
        "    test_train_split(print_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVdltRn4nS1t"
      },
      "outputs": [],
      "source": [
        "def count_training_samples():\n",
        "    # function to count the number of samples (paragraphs) for the training corpus\n",
        "    return sum([len(doc['annotations']) for doc in annotations_training])\n",
        "\n",
        "def count_dev_samples():\n",
        "    # function to count the number of samples (paragraphs) for the training corpus\n",
        "    return sum([len(doc['annotations']) for doc in annotations_dev])\n",
        "\n",
        "def get_annotated_entities(annotations):\n",
        "    # function to get all entities in a hand-annotated doc (all lines)\n",
        "    return [line[1]['entities'] for line in annotations if line]\n",
        "\n",
        "def get_text(annotations):\n",
        "    # function to get all raw text from the hand-annotated doc (all lines)\n",
        "    return [line[0] for line in annotations if line]\n",
        "\n",
        "def get_annotations(print_output=False):\n",
        "    global annotated_entities_training, annotated_entities_dev, annotated_text_training, annotated_text_dev\n",
        "    \"\"\"Note: Entities to be stored in the form [[[element1, element2]],[[element1, element2]]]\n",
        "    \"\"\"\n",
        "    # run function to get all entities from all lines in all the passed-in hand-annotated docs\n",
        "    annotated_entities_training = [get_annotated_entities(doc['annotations']) for doc in annotations_training]\n",
        "    annotated_entities_dev = [get_annotated_entities(doc['annotations']) for doc in annotations_dev]\n",
        "    # run function to get all text from all lines in all the passed-in hand-annotated docs\n",
        "    annotated_text_training = [get_text(doc['annotations']) for doc in annotations_training]\n",
        "    annotated_text_dev = [get_text(doc['annotations']) for doc in annotations_dev]\n",
        "    \"\"\"Note: Annotated text stored in form [[line1, line1],[line1, line2]]\n",
        "    i.e., a list of document-lists of lines\"\"\"\n",
        "\n",
        "    if print_output:\n",
        "        # print total counts of annotated documents; lines and entities\n",
        "        print(f'Number of training documents: {len(annotated_entities_training)}')\n",
        "        print(f'Number of training samples (paragraphs) in training documents: {count_training_samples()}')\n",
        "        print(f'Number of dev documents: {len(annotated_entities_dev)}')\n",
        "        print(f'Number of dev samples (paragraphs) in dev documents: {count_dev_samples()}')\n",
        "        print(f'Number of training lines: {sum([len(x) for x in annotated_entities_training])}')\n",
        "        print(f'Number of dev lines: {sum([len(x) for x in annotated_entities_dev])}')\n",
        "        print(f'Number of training entities: {sum([sum(len(y) for y in x ) for x in annotated_entities_training])}\\n')\n",
        "        print(f'Number of dev entities: {sum([sum(len(y) for y in x ) for x in annotated_entities_dev])}\\n')\n",
        "        # print first entity, of first line, of first doc, to verify entities\n",
        "        print(f'Annotated entities training sample (doc 4, line 1): {annotated_entities_training[3][0]}\\n')\n",
        "        print(f'Annotated entities dev sample (doc 1, line 1): {annotated_entities_dev[0][0]}\\n')\n",
        "        # print sample of annotated text to verify\n",
        "        print(f'Annotated text training sample (doc 2, line 1): {annotated_text_training[1][0]}\\n')\n",
        "        print(f'Annotated text dev sample (doc 1, line 1): {annotated_text_dev[0][0]}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kABeOc0nS1v"
      },
      "outputs": [],
      "source": [
        "def compile_training_data(print_output):\n",
        "    global training_data, dev_data\n",
        "    training_data = dict()\n",
        "    dev_data = dict()\n",
        "    training_annotations = list()\n",
        "    dev_annotations = list()\n",
        "\n",
        "    for doc_idx, doc in enumerate(annotated_entities_training):\n",
        "        for line_idx, line in enumerate(doc):\n",
        "            ents = list()\n",
        "            for ent in line:\n",
        "                ents.append((ent[0], ent[1], ent[2]))\n",
        "            training_annotations.append({'entities': ents, 'text': annotated_text_training[doc_idx][line_idx]})\n",
        "    training_data['classes'] = labels_of_interest\n",
        "    training_data['annotations'] = training_annotations\n",
        "\n",
        "    for doc_idx, doc in enumerate(annotated_entities_dev):\n",
        "        for line_idx, line in enumerate(doc):\n",
        "            ents = list()\n",
        "            for ent in line:\n",
        "                ents.append((ent[0], ent[1], ent[2]))\n",
        "            dev_annotations.append({'entities': ents, 'text': annotated_text_dev[doc_idx][line_idx]})\n",
        "    dev_data['classes'] = labels_of_interest\n",
        "    dev_data['annotations'] = dev_annotations\n",
        "\n",
        "    # print sample of compiled annotation training data\n",
        "    print(f'Training data sample (doc 1, line 1): {training_data.get(\"annotations\")[2]}\\n') if print_output else None\n",
        "    # print sample of compiled annotation dev data\n",
        "    print(f'Training data sample (doc 1, line 1): {dev_data.get(\"annotations\")[2]}\\n') if print_output else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zN2ZW4wnS1v"
      },
      "outputs": [],
      "source": [
        "def prepare_training(print_output):\n",
        "\n",
        "    nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "\n",
        "    def create_spacy_file(path, filename, data):\n",
        "      doc_bin = DocBin() # create a DocBin object\n",
        "      skipped_ent_count = 0\n",
        "      filtered_ents_count = 0\n",
        "      for idx, training_line in tqdm(enumerate(data)):\n",
        "          text = training_line['text']\n",
        "          labels = training_line['entities']\n",
        "          doc = nlp.make_doc(text) \n",
        "          ents = []\n",
        "          skipped_ents = 0\n",
        "          for start, end, label in labels:\n",
        "              span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "              if span is None:\n",
        "                  skipped_ents += 1\n",
        "              else:\n",
        "                  ents.append(span)\n",
        "          filtered_ents = filter_spans(ents)\n",
        "          skipped_ent_count += skipped_ents\n",
        "          filtered_ents_count += len(filtered_ents)\n",
        "          doc.ents = filtered_ents \n",
        "          doc_bin.add(doc)\n",
        "      print(f'Number of skipped entities: {skipped_ent_count}') if print_output else None\n",
        "      print(f'Number of filtered entities: {filtered_ents_count}') if print_output else None\n",
        "      doc_bin.to_disk(path + filename) # save the docbin object\n",
        "  \n",
        "    # create training data\n",
        "    create_spacy_file(docbin_object_path, docbin_object_training_filename, data=training_data['annotations'])\n",
        "    # create dev data\n",
        "    create_spacy_file(docbin_object_path, docbin_object_dev_filename, data=dev_data['annotations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu_wk-6kJsii"
      },
      "outputs": [],
      "source": [
        "def mount_google_drive():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph64Wvf3nS1w"
      },
      "outputs": [],
      "source": [
        "# run training\n",
        "colab = 1  # boolean, True if using Google Colab, else False\n",
        "mount_google_drive() if colab else None  # arguments: mount google drive if on colab? (boolean)\n",
        "setup(1, colab)  # arguments: print output? (boolean), running on colab? (boolean)\n",
        "get_annotations(1)  # arguements: print output? (boolean)\n",
        "compile_training_data(1)  # arguements: print output? (boolean)\n",
        "prepare_training(1)  # arguements: print output? (boolean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-VWNd6CnS1x"
      },
      "outputs": [],
      "source": [
        "# Train using CPU\n",
        "# add defaults to base config created at https://spacy.io/usage/training#quickstart\n",
        "#!python -m spacy init fill-config /content/drive/MyDrive/data/base_config_cnn_accuracy.cfg /content/drive/MyDrive/data/config.cfg\n",
        "\n",
        "# train the model (CPU)\n",
        "#!python -m spacy train /content/drive/MyDrive/data/config.cfg --output /content/drive/MyDrive/data/ --paths.train /content/drive/MyDrive/data/docbin/training_data.spacy --paths.dev /content/drive/MyDrive/data/docbin/dev_data.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzJQCkTR0WoM"
      },
      "outputs": [],
      "source": [
        "# Train using GPU\n",
        "# add defaults to base config created at https://spacy.io/usage/training#quickstart\n",
        "\n",
        "!python -m spacy init fill-config /content/drive/MyDrive/config/base_config_transformer_accuracy.cfg /content/drive/MyDrive/config/config.cfg\n",
        "\n",
        "# train the model (GPU)\n",
        "!python -m spacy train /content/drive/MyDrive/config/config.cfg --output /content/drive/MyDrive/models/ --paths.train /content/drive/MyDrive/data/docbin/training_data.spacy --paths.dev /content/drive/MyDrive/data/docbin/training_data.spacy --gpu-id 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.15 ('uhi-ZQVV2iWc')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "65f88eacf3a10b22e2367da6754b23494b2804a02fe03c23afbe72788a968f5d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
