{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "- Script name: run_ner_model.\n",
    "- Author: Dan Bright, cosmoid@tuta.io.\n",
    "- Description: Script to run NER model on raw data.\n",
    "- Version: 0.1.\n",
    "\"\"\"\n",
    "\n",
    "# Install required packages if not already present on system\n",
    "#!pip install matplotlib spacy numpy pandas spacy_stanza spacy-transformers openai\n",
    "\n",
    "# declare imports\n",
    "import spacy, openai, os, re, html, json, ast\n",
    "import pandas as pd\n",
    "from spacy import language\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData:\n",
    "    \"\"\"\n",
    "    Class that cleans and prepares the data training &\n",
    "\n",
    "    Consumes:\n",
    "        - input_data: list[tuple] = list of input data to clean, in form [(record_id:int, text:str)]\n",
    "        - separate_slashes: bool = whether to separate slashes by a space [True|False]\n",
    "        - remove_linebreaks: bool = whether to remove linebreaks & join by a space [True|False]\n",
    "        - remove_non_alphanum: bool = whether to remove all non-alphanumeric characters [True|False]\n",
    "        - ensure_encoding: bool = ensure all characters are correctly encoded (True|False)\n",
    "    Produces:\n",
    "        - list of cleaned data, in form [(record_id:int, text:str)]\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(\n",
    "        cls,\n",
    "        input_data: list[tuple] = [],\n",
    "        separate_slashes: bool = True,  # Default to True\n",
    "        remove_linebreaks: bool = True,  # Default to True\n",
    "        remove_non_alphanum: bool = True,  # Default to True\n",
    "        ensure_encoding: bool = True,  # Default to True\n",
    "    ) -> list[tuple]:\n",
    "        obj = super().__new__(cls)\n",
    "        return obj._run_filters(\n",
    "            docs=input_data,\n",
    "            separate_slashes=separate_slashes,\n",
    "            remove_linebreaks=remove_linebreaks,\n",
    "            remove_non_alphanum=remove_non_alphanum,\n",
    "            ensure_encoding=ensure_encoding,\n",
    "        )\n",
    "\n",
    "    def _run_filters(\n",
    "        self,\n",
    "        docs,\n",
    "        separate_slashes,\n",
    "        remove_linebreaks,\n",
    "        remove_non_alphanum,\n",
    "        ensure_encoding,\n",
    "    ) -> list[tuple]:\n",
    "        \"\"\"\n",
    "        Method to iterate the data & run filters.\n",
    "        Returns: list of cleaned data in form [(record_id:int, text:str)]\n",
    "        \"\"\"\n",
    "        filtered_docs: list[tuple] = []\n",
    "        for record in docs:\n",
    "            record_txt: str = record[1]\n",
    "            record_txt = (\n",
    "                self._separate_slashes(record_txt) if separate_slashes else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._remove_linebreaks(record_txt) if remove_linebreaks else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._remove_non_alphanum(record_txt)\n",
    "                if remove_non_alphanum\n",
    "                else record_txt\n",
    "            )\n",
    "            record_txt = (\n",
    "                self._ensure_encoding(record_txt) if ensure_encoding else record_txt\n",
    "            )\n",
    "            filtered_docs.append((record[0], record_txt))\n",
    "        return filtered_docs\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_encoding(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to ensure characters are encoded correctly\n",
    "        (i.e., no html entities, etc)\n",
    "        \"\"\"\n",
    "        return html.unescape(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def _separate_slashes(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to ensure all slashes within strings are surrounded by\n",
    "        whitespace.\n",
    "        \"\"\"\n",
    "        return re.sub(r\"(?<!\\s)/(?!\\s)\", \" / \", input)\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_linebreaks(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to remove paragraphs breaks.\n",
    "        \"\"\"\n",
    "        return \" \".join(input.splitlines())\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_non_alphanum(input: str) -> str:\n",
    "        \"\"\"\n",
    "        Method to remove all non-alphanumeric characters, except:\n",
    "          - whitespaces\n",
    "          - dots\n",
    "          - forward slashes\n",
    "        \"\"\"\n",
    "        return re.sub(r\"\\s+\", \" \", re.sub(r\"[^\\w\\s\\.\\/]+\", \"\", input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunNERModel:\n",
    "    \"\"\"\n",
    "    Class that evaluates performance of NER models.\n",
    "\n",
    "    Consumes:\n",
    "        - jupyter: bool = whether script is being run as a Jupyter notebook.\n",
    "        - model_uri: str = URI of model (local path or name on remote API)\n",
    "        - model_type: str = string representing model type (from: [GPT, SPACY])\n",
    "        - docs: list[tuple] = list of documents to run NER on, in form [(record_id:int, text:str)]\n",
    "        - openai_key: str = openAPI key\n",
    "        - gpt_prompt_sep: str = GPT prompt separator token (if any)\n",
    "        - gpt_comp_sep: str = GPT completion separator token (if any)\n",
    "        - output_record_id_name: str = Key / column name to assign to record ID\n",
    "    Produces:\n",
    "        - python dictionary containing NER results, in form [{\"RECORD_ID\": 1, \"REP_CITY\": [\"New York\"]}]\n",
    "    Notes:\n",
    "        - Record number is derived from the filenames of the consumed text files, which\n",
    "          MUST be named according to the convention of `record_n.txt`, where n is record number.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        jupyter: bool = True,  # default True\n",
    "        model_uri: str = \"\",  # no default\n",
    "        model_type: str = \"\",  # no default\n",
    "        docs: list[tuple] = [],  # no default\n",
    "        openai_key: str = \"\",  # no default\n",
    "        gpt_prompt_sep: str = \"\",  # no default\n",
    "        gpt_comp_sep: str = \"\",  # no default\n",
    "        output_record_id_name: str = \"\",  # no default\n",
    "    ) -> list[dict]:\n",
    "        # define variables\n",
    "        self._jupyter: bool = jupyter\n",
    "        self._model_type = model_type.upper()\n",
    "        self._model_uri: str = model_uri\n",
    "        self._spacy_nlp: language.Doc = None\n",
    "        self._docs: list[tuple] = docs\n",
    "        self._openai_key: str = openai_key\n",
    "        self._gpt_prompt_sep = gpt_prompt_sep\n",
    "        self._gpt_comp_sep = gpt_comp_sep\n",
    "        self._gpt_results: list[tuple] = []  # in form [(record_num, str)]\n",
    "        self._spacy_results: list[tuple] = []  # in form [(record_num, str)]\n",
    "        self._results_formatted: list[dict] = []  # in form [(record_num, str)]\n",
    "        self._output_record_id_name: str = output_record_id_name\n",
    "        # run methods [note: do not change running order]\n",
    "        if self._model_type == \"GPT\":\n",
    "            self._run_gpt()\n",
    "            self._format_gpt_results()\n",
    "        elif self._model_type == \"SPACY\":\n",
    "            self._run_spacy()\n",
    "            self._format_spacy_results()\n",
    "\n",
    "    def get_results(self) -> list[dict]:\n",
    "        # return results\n",
    "        return self._results_formatted\n",
    "\n",
    "    def _run_spacy(self) -> None:\n",
    "        # method to run spacy model\n",
    "        self._spacy_nlp: language.doc = spacy.load(self._model_uri)\n",
    "\n",
    "    def _run_gpt(self) -> None:\n",
    "        # method to run GPT\n",
    "        openai.api_key = self._openai_key\n",
    "        for doc in self._docs:\n",
    "            self._gpt_results.append(\n",
    "                (\n",
    "                    doc[0],\n",
    "                    openai.Completion.create(\n",
    "                        model=self._model_uri,\n",
    "                        prompt=f\"{doc[1]}{self._gpt_prompt_sep}\",\n",
    "                        max_tokens=1500,\n",
    "                        temperature=0.2,\n",
    "                        top_p=0.1,\n",
    "                        frequency_penalty=0,\n",
    "                        presence_penalty=0,\n",
    "                        stop=[self._gpt_comp_sep],\n",
    "                    )[\"choices\"][0][\"text\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _format_gpt_results(self) -> None:\n",
    "        # method to format GPT results ahead of export\n",
    "        for result in self._gpt_results:\n",
    "            ent_list: list[str] = result[1].splitlines()\n",
    "            ent_list: list = result[1].splitlines()\n",
    "            results: dict = {}\n",
    "            results = {self._output_record_id_name: result[0]}\n",
    "            for ents in ent_list:\n",
    "                if \":\" in ents:\n",
    "                    key, value = ents.split(\":\", 1)\n",
    "                    results[key.strip()] = ast.literal_eval(value)\n",
    "            self._results_formatted.append(results)\n",
    "\n",
    "    def _format_spacy_results(self) -> None:\n",
    "        # method to format spaCy results ahead of export\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportResults:\n",
    "    \"\"\"\n",
    "    Class that exports the results as JSON and XLSX files\n",
    "\n",
    "    Consumes:\n",
    "        - output_record_id_name: str = Key / column name to assign to record ID\n",
    "        - output_xlsx_sort_col: str =  name of col to sort output XLSX by (string)\n",
    "        - output_json_path: str = path to output JSON file\n",
    "        - output_xlsx_path: str = path to output XLSX file\n",
    "        - output_xlsx_melt: bool = reshape output XLSX using Pandas to yield RECORD_ID, NAME, VALUE\n",
    "        - results_formatted: list[dict] = list of results\n",
    "    Produces:\n",
    "        - JSON formatted file containing tokens (strings) that were extracted.\n",
    "        - EXCEL formatted file containing tokens (strings) that were extracted.\n",
    "    Notes:\n",
    "        -\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_record_id_name: str = \"RECORD_ID\",  # default RECORD_ID\n",
    "        output_xlsx_sort_col: str = \"RECORD_ID\",  # default RECORD_ID\n",
    "        output_json_path: str = \"\",  # no default\n",
    "        output_xlsx_path: str = \"\",  # no default\n",
    "        output_xlsx_melt: bool = False,  # default False\n",
    "        results_formatted: list[dict] = [],  # default empty list\n",
    "    ) -> None:\n",
    "        # define variables\n",
    "        self._output_record_id_name: str = output_record_id_name\n",
    "        self._output_xlsx_sort_col: str = output_xlsx_sort_col\n",
    "        self._output_json_path: str = output_json_path\n",
    "        self._output_xlsx_path: str = output_xlsx_path\n",
    "        self._output_xlsx_melt: bool = output_xlsx_melt\n",
    "        self.results_formatted: list[dict] = results_formatted\n",
    "\n",
    "    def write_json_output(self) -> None:\n",
    "        # writes formatted output to JSON file\n",
    "        with open(self._output_json_path, \"w\") as fp:\n",
    "            json.dump(self.results_formatted, fp)\n",
    "\n",
    "    def write_xlsx_output(self) -> None:\n",
    "        # writes formatted output to EXCEL file\n",
    "        df = pd.read_json(json.dumps(self.results_formatted))\n",
    "        if self._output_xlsx_melt:\n",
    "            df = pd.melt(\n",
    "                df,\n",
    "                id_vars=[self._output_record_id_name],\n",
    "                value_vars=[e for e in self.results_formatted[0].keys()],\n",
    "                var_name=\"NAME\",\n",
    "                value_name=\"VALUE\",\n",
    "            )\n",
    "            df = df.dropna(subset=[\"VALUE\"]).sort_values(self._output_xlsx_sort_col)\n",
    "        df.to_excel(self._output_xlsx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecuteNER:\n",
    "    \"\"\"\n",
    "    Class that evaluates performance of NER models.\n",
    "\n",
    "    Consumes:\n",
    "        - jupyter: bool = whether script is being run as a Jupyter notebook.\n",
    "        - doc_dir: str = path to directory containing input documents.\n",
    "        - model_uri: str = URI of model (local path or name on remote API).\n",
    "        - model_type: str = string representing model type (from: [GPT, SPACY]).\n",
    "        - openai_key: str = openAPI key.\n",
    "        - gpt_prompt_sep: str = GPT prompt separator token (if any).\n",
    "        - gpt_comp_sep: str = GPT completion separator token (if any).\n",
    "        - output_record_id_name: str = Key / column name to assign to record ID.\n",
    "        - output_xlsx_sort_col: str =  name of col to sort output XLSX by (string).\n",
    "        - output_json_path: str = path to output JSON file.\n",
    "        - output_xlsx_path: str = path to output XLSX file.\n",
    "        - output_xlsx_melt: bool = reshape output XLSX using Pandas to yield RECORD_ID, NAME, VALUE.\n",
    "        - results_formatted: list[dict] = list of results.\n",
    "        - export_json: bool = export as JSON?\n",
    "        - export_xlsx: bool = export as xlsx?\n",
    "        - batch_size: int = processing batch size.\n",
    "    Produces:\n",
    "        - JSON formatted file containing tokens (strings) that were extracted.\n",
    "        - EXCEL formatted file containing tokens (strings) that were extracted.\n",
    "    Notes:\n",
    "        - Record number is derived from the filenames of the consumed text files, which\n",
    "          MUST be named according to the convention of `record_n.txt`, where n is record number.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        jupyter,\n",
    "        doc_dir,\n",
    "        model_uri,\n",
    "        model_type,\n",
    "        openai_key,\n",
    "        output_json_path,\n",
    "        output_xlsx_path,\n",
    "        output_xlsx_melt,\n",
    "        output_xlsx_sort_col,\n",
    "        output_record_id_name,\n",
    "        export_json,\n",
    "        export_xlsx,\n",
    "        batch_size,\n",
    "        gpt_prompt_sep,\n",
    "        gpt_comp_sep,\n",
    "    ) -> None:\n",
    "        # define variables\n",
    "        self._output_json_path = output_json_path\n",
    "        self._output_xlsx_path = output_xlsx_path\n",
    "        self._output_xlsx_melt = output_xlsx_melt\n",
    "        self._output_xlsx_sort_col = output_xlsx_sort_col\n",
    "        self._output_record_id_name = output_record_id_name\n",
    "        self._export_json = export_json\n",
    "        self._export_xlsx = export_xlsx\n",
    "        self._batch_size = batch_size\n",
    "        self._jupyter = jupyter\n",
    "        self._model_uri = model_uri\n",
    "        self._model_type = model_type\n",
    "        self._openai_key = openai_key\n",
    "        self._gpt_prompt_sep = gpt_prompt_sep\n",
    "        self._gpt_comp_sep = gpt_comp_sep\n",
    "        self._all_results: list[dict] = []  # results from all batches\n",
    "        self._doc_dir: Path = Path(doc_dir).resolve(strict=True)\n",
    "        self._docs: list[tuple] = []\n",
    "        self._doc_batches: list[list] = []\n",
    "        # run methods [note: do not change running order]\n",
    "        self._get_docs()\n",
    "        self._prepare_data()\n",
    "        self._batchify()\n",
    "        self._run_model()\n",
    "        self._export_results()\n",
    "\n",
    "    def get_results(self) -> list[dict]:\n",
    "        return self._all_results\n",
    "\n",
    "    def _get_docs(self) -> None:\n",
    "        for filepath in self._doc_dir.glob(\"*.txt\"):\n",
    "            with open(filepath, \"r\") as file:\n",
    "                data_txt: str = file.read()\n",
    "                self._docs.append((int(re.findall(r\"\\d+\", filepath.stem)[0]), data_txt))\n",
    "                self._docs = sorted(self._docs, key=lambda x: x[0])\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        self._docs = CleanData(self._docs)\n",
    "\n",
    "    def _batchify(self) -> None:\n",
    "        for i in range(0, len(self._docs), self._batch_size):\n",
    "            self._doc_batches.append(self._docs[i : i + self._batch_size])\n",
    "\n",
    "    def _run_model(self) -> None:\n",
    "        for idx, batch in enumerate(self._doc_batches):\n",
    "            try:\n",
    "                self._all_results += RunNERModel(\n",
    "                    jupyter=self._jupyter,\n",
    "                    model_uri=self._model_uri,\n",
    "                    model_type=self._model_type,\n",
    "                    docs=batch,\n",
    "                    openai_key=self._openai_key,\n",
    "                    gpt_prompt_sep=self._gpt_prompt_sep,\n",
    "                    gpt_comp_sep=self._gpt_comp_sep,\n",
    "                    output_record_id_name=self._output_record_id_name,\n",
    "                ).get_results()\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred with batch {idx}: {str(e)}\")\n",
    "\n",
    "    def _export_results(self) -> None:\n",
    "        export = ExportResults(\n",
    "            output_xlsx_sort_col=self._output_xlsx_sort_col,\n",
    "            output_json_path=self._output_json_path,\n",
    "            output_xlsx_path=self._output_xlsx_path,\n",
    "            output_xlsx_melt=self._output_xlsx_melt,\n",
    "            results_formatted=self._all_results,\n",
    "        )\n",
    "        if self._export_json:\n",
    "            export.write_json_output()\n",
    "        if self._export_xlsx:\n",
    "            export.write_xlsx_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script\n",
    "\n",
    "# script parameters\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "JUPYTER: bool = True  # Running on Jupyter notebook? (True|False)\n",
    "MODEL_URI: str = \"davinci:ft-uplandsdynamic-2023-07-05-14-10-39\"  # URI of model (local path or name on remote API) (string)\n",
    "MODEL_TYPE: str = \"GPT\"  # Model type, from [\"GPT\", \"SPACY\"] (string)\n",
    "DOC_DIR: str = \"../../data/sample/test/txt/tiny_test\"  # Directory containing formatted txt files (`docs`) for NER (string)\n",
    "GPT_PROMPT_SEP: str = \"\\n\\n###\\n\\n\"  #  GPT prompt separator token (if any) (string)\n",
    "GPT_COMPLETION_SEP: str = \"\\n\\nEND\\n\\n\"  # GPT completion separator token (if any) (string)\n",
    "OUTPUT_XLSX_SORT_COL: str = \"RECORD_ID\"  # name of col to sort output XLSX by (string)\n",
    "OUTPUT_RECORD_ID_NAME: str = \"RECORD_ID\"  # name to assign to record ID key/column in output XLSX / JSON (if any) (string)\n",
    "EXPORT_JSON: bool = True  # write results output to JSON file? (True|False)\n",
    "EXPORT_XLSX: bool = True  # write results output to XLSX file? (True|False)\n",
    "OUTPUT_JSON_PATH: str = \"../../data/output/ner/test_result_gpt.json\"  # Path > output JSON\n",
    "OUTPUT_XLSX_PATH: str = \"../../data/output/ner/test_result_gpt.xlsx\"  # Path > output XLSX\n",
    "OUTPUT_XLSX_MELT: bool = True  # reshape output XLSX using Pandas to yield RECORD_ID, NAME, VALUE (True|False)\n",
    "BATCH_SIZE: int = 5  # size of batches to send for NER\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = ExecuteNER(\n",
    "        doc_dir=DOC_DIR,\n",
    "        output_record_id_name=OUTPUT_RECORD_ID_NAME,\n",
    "        output_xlsx_sort_col=OUTPUT_XLSX_SORT_COL,\n",
    "        output_json_path=OUTPUT_JSON_PATH,\n",
    "        output_xlsx_path=OUTPUT_XLSX_PATH,\n",
    "        output_xlsx_melt=OUTPUT_XLSX_MELT,\n",
    "        export_json=EXPORT_JSON,\n",
    "        export_xlsx=EXPORT_XLSX,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        jupyter=JUPYTER,\n",
    "        model_uri=MODEL_URI,\n",
    "        model_type=MODEL_TYPE,\n",
    "        openai_key=OPENAI_API_KEY,\n",
    "        gpt_prompt_sep=GPT_PROMPT_SEP,\n",
    "        gpt_comp_sep=GPT_COMPLETION_SEP,\n",
    "    ).get_results()\n",
    "\n",
    "    print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scu-GcmJu1Nh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
